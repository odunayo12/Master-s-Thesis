\chapter{The Euler-Poisson Scheme}
\section{Preliminaries}
We consider a $\mathbb{R}^d$-valued adapted stochastic process $Y= (Y_t)_{t \in [0, T]}$ defined on the filtered probability space $(\Omega , \mathcal{F}, (\mathcal{F})_{t \geq 0}, \mathcal{P})$, which is a strong solution to the SDE (\ref{eq_1}) which is restated here for convenience 
\begin{equation}\label{eq_major}
      Y_t = y_0  + \int_0^t a(Y_{s^-})dX_s \qquad t \in [0, \, T].
\end{equation}
where $y_0  \in \mathbb{R}^d$ is the deterministic initial value; $a : \mathbb{R}^d \to \mathbb{R}^{d \times d}
$ is a coefficient function, on which we impose a standard Lipschitz assumption implying the  existence and strong uniqueness of the solution. The smoothness of $a$  is specified in the sequel.  $X=(X
_t)_{t\in [0,T]}
 $ is a $d$-dimensional jump of L\'evy process. We write ${Y}_{t^-}$ instead of ${Y}_{t}$ in order that the integrand be predictable,
so the integral is well defined as an It\^o integral with $${Y}_{t^-} = \lim_{s \uparrow t}Y_s.$$
For the Euler-Poison Scheme, we assume that the marginals of the process is are in $L^2 (\Omega , \mathcal{F}, \mathcal{P})$ hence omit the truncation function, leading to the  so called characteristic exponent of the L\'evy process expressed as 
\begin{equation*}
    \mathbb{E}[e^{i\langle \vartheta, X_t\rangle}] = e^{t\Psi(\vartheta)} \qquad \forall \, \vartheta \in \mathbb{R}^d
\end{equation*}
where
\begin{equation}\label{inf_div_dist_levy}
    \Psi(\vartheta) = -\frac{1}{2}\langle \vartheta, \Sigma \Sigma^T \vartheta \rangle + i\langle b, \vartheta \rangle + \int_{\mathbb{R}^d} \big( e^{i\langle \vartheta,x \rangle } - 1 - {i\langle \vartheta,x \rangle }\big) \, v(dx) 
\end{equation}
satisfying the assumptions of Theorem \ref{Thm_LK}. The distribution of $X$ is uniquely characterized by the triplet $(b, \, \Sigma,\, v)$ and $\langle \cdot, \cdot
\rangle$ is the usual inner product. \\
Denoting by $W=(W_t)_{t\in [0,T]} $ a $d$-dimensional Wiener process independent of independent of $L$, where $L=(L_t)_{t\in [0,T]}$ is the compensated jump process expressed in (\ref{eq_217}) which is an $L^2$-martingale, see for example \cite{applebaum2009levy}. From Proposition \ref{levy_Ito_decop}, the L\'evy-Ito decomposition guarantees that every  $L^2$-L\'evy process has the representation 
\begin{equation}
X_t = \Sigma W_t + L_t + bt
\end{equation}We impose the following conditions on our variables for tractability of our numerical analysis. 
\begin{assumption} There exist a constant $k \in \mathbb{R}_+$ such that 
\begin{equation*}
\int_{\mathbb{R}^d} (1 \land |x|^2)  v(dx) \leq k^2, |\Sigma|\leq k, |b|\leq k, |y_0|\leq k
\end{equation*}
\end{assumption}\\
The following Theorem set up the usual condition that guarantees the existence of
 a unique strong solution to (\ref{eq_major}) 








The focus of this thesis is the modification of the standard Euler scheme, which entails the substitution of uniformly spaced time steps by exponentially distributed time steps.Thus, the grid points presented in this scheme can be thought of as arrival times of a Poisson process. For $n \geq 1 ,$ let $ \xi (n/T) := (\xi_{i})_{i \geq 1}$  be a sequence on independent identically distributed (i.i.d) random variables defined on the probability space  $(\Omega, \mathcal{F}, \mathcal{P}),$ where each $\xi_i$ is an exponentially distributed random variable with rate $n/T$ denoted by  $\xi_{i} \sim Exponential(n/T)$ such that $\mathbb{E}[ (\xi_{i})]= T/n $ and denote further by $\mathcal{F}^{\xi} := \sigma( \xi_{i} ; \,  i \geq 1)$ the sigma algebra generated by $ \xi_i $; which is assumed to be independent of $X$, and set  $\xi_{0} = 0$ and omit the dependence of $\xi $ on $(n/T)$ for simplicity of notation. \\
We recall that the Euler for approximation of Stochastic Differential Equations is given on a time grid $0 = t_0 < t_1 < \ldots t_n$ by
\begin{equation*}
\tilde{Y}_{t_{i}} := \tilde{Y}_{t_{i-1}} + a(\tilde{Y}_{t_{i-1}})\Delta W_{t_{i-1}},  \qquad \qquad
  \tilde{Y}_0 = y_0 \qquad \qquad  i = 1, 2, \ldots n-1 
\end{equation*}
Where $\Delta W_{t_{i-1}} := W_{t_{i}}-W_{t_{i-1}}$ is the increment of the Wiener Process $W$ and $\Delta W_{t_{i}} \sim N (0, \, \Delta_{t_{i}})$, that is, the increment follows an independent Gaussian distribution; whereas, its jump adapted counterpart which we name the Euler-Poisson Scheme is then given by the sequence $\tilde{Y} := (\tilde{Y}_{t_i})_{i\geq 0}$ defined as 
\begin{equation}\label{eq5}
\tilde{Y}_{t_{i}} := \tilde{Y}_{t_{i-1}} + a(\tilde{Y}_{t_{i-1}})\Delta X_{\xi_{i}},  \qquad \qquad
  \tilde{Y}_0 = y_0 \qquad \qquad  i = 1, 2, \ldots 
\end{equation}
with independent and stationary increment given by $\Delta X_{\xi_{i}} :=  X_{\xi_{i}} - X_{\xi_{i-1}} \overset{d}{=}  X_{\xi}$. Since each $\xi_{i}$ is independent and follows an exponential distribution, it coincides with the definition of interarrival time described in Proposition \ref{prop_Poisson}; thus, we can define the random grid $(t_{i})_{i \geq 0}$ given by the arrival times of a Poisson process as the partial sum of sequences of these $\xi_{i}$'s, this we specify as 
\begin{equation*}
 t_{i} := \sum_{j=0}^{i}  \xi_{j},
\end{equation*}
where the Poisson process is given by $\mathcal{N}(n/T) = \mathcal{N} := (\mathcal{N}_{t})_{t \geq 0}$. It is noteworthy that $t_{i} \overset{d}{=} \Gamma(i, \, n/T)$ representing an Gamma distribution with shape parameter $i$ and rate parameter $n/T$ further, the mean $\mathbb{E}[ (\xi_{i})]= T/n$ corresponds to the time-steps of the deterministic spaced Euler scheme. Based on the foregoing construction, the  claim here is that $\tilde{Y}_{t_n}$ is an approximation of the solution $Y$ at endpoints $Y_T$ and the aim of this work is to derive the asymptotic behavior of 
\begin{equation}\label{eq6}
\lim_{n\to\infty} \mathbb{E}[|Y_T - \tilde{Y}_{t_n}|^2]
\end{equation}
In order to carry out the numerical analysis, an interpolant, which stochastically interpolates the Euler-Poisson scheme is introduced: let $\iota(t)$ denote the largest grid point before $t$ in this scheme, expressed as:
\begin{equation*}
\iota(t) = sup[0, \, t] \cap (t_{i})_{t \geq 0}
\end{equation*}
and define 
\begin{equation}\label{eq7}
\hat{Y}_{t} = y_0 + \int^t_{0} a(\hat{Y}_{\iota(s^-)})dX_s = \hat{Y}_{\iota(t)} + a(\hat{Y}_{\iota(t)})(X_s - X_{\iota(t)}) \qquad t \in [0, t_n \lor T]
\end{equation}
Observe that for $t \in [t_i, \, t_{i+1})$ we have $\hat{Y}_{t_i}= \tilde{Y}_{t_n} = Y_{\iota(t)}$, that is, the processes coincide almost surely for all random times $(t_{i})_{t \geq 0}$. Therefore, $ \hat{Y} = (\hat{Y})_{t \in [0, t_n \lor T]} $ interpolates, in a random way, the chain $\tilde{Y}$. Furthermore, another important variable crucial to the derivations hereafter executed in this work is the largest gap of the random grid $(t_{i})_{t \geq 0}$ restricted to $[0, T]$. Denote this $\mathcal{F}^{\xi}$-measurable random variable by
\begin{equation}\label{eq8}
\tau := \sup_{s \in [0, T] } (s - \iota (s))
\end{equation}
We include the following Lemma to show the moments of $\tau$



\section{Some errors }
A counting process is said to be a Poisson process with rate $\lambda > 0$, if 
\begin{equation}\label{arr_Poisson}
    N_t = \sum_{n \geq 1} T_i\mathbbm{1}_{(0, t]}, \qquad t \geq 0
\end{equation}
for a sequence $(T_i)_{i \geq 1}$ having independent and identically distributed increments $(T_i - T_{i-1})_{i \geq 1} =: (\xi_i)_{i \geq 1}$, where $\xi_i \sim Exponential(\lambda)$. The $T_i$ is called jump or arrival time while the $\xi_i$ is called interarrival time associated with the Poisson process $(N_t)_{t \geq 0}$

\begin{proof}
That the process $(N_t)_{t \geq 0}$ is completely determined by its associated arrival times $(T_i)_{i \geq 1}$ is clear from (\ref{arr_Poisson}). Hence, the equivalence of Proposition \ref{prop_Poisson} and Definition \ref{POisson_1} follows from Remark \ref{remark_Gamma}(\textit{ii}) and satisfies ($p^{\star}$)-($p^{\star \star \star}$). While ($p^{\star}$) holds trivially true, for ($p^{\star \star \star}$) we have that 
\begin{align*}
\mathcal{P}(N_t = \kappa) &= \mathcal{P}(T_{\kappa} \leq t < T_{\kappa} + \xi_{\kappa + 1} )= \int_0^t \mathcal{P}(\xi_{\kappa + 1}> t-s) \Gamma(\kappa,\lambda) ds\\
&= \int_0^t e^{-\lambda (t-s)}\dfrac{\lambda^{\kappa} s^{\kappa-1} }{ (\kappa-1)!}e^{-\lambda s} ds = \dfrac{\lambda^{\kappa} }{ (\kappa-1)!}e^{-\lambda t} \int_0^t  s^{\kappa-1} ds\\
&= \dfrac{(\lambda t)^{\kappa} }{\kappa!}e^{-\lambda t}\mathbbm{1}_{\kappa > 0} \qquad \forall t>0.
\end{align*}
Thus showing that $ N_t \sim Poisson(\lambda t)$. Finally it remains to show that increment property of  $(N_t)_{t \geq 0}$ given by ($p^{\star \star \star}$) holds. This clearly follows from memoryless property of the exponential distribution whose proof we omit here but can be found in many literature; for example see \morecite{tankov2003financial}.  
\end{proof}


define the random grid $(t_{i})_{i \geq 0}$ given by the arrival times of a Poisson process as the partial sum of sequences of these $\xi_{i}$'s, this we specify as 